{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d71bc261-6e78-4691-90ad-8e98eecc3221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import zipfile\n",
    "# from tqdm.auto import tqdm, trange # original\n",
    "from tqdm.notebook import tqdm, trange # fix for newline issue?\n",
    "from glob import glob\n",
    "from joblib import delayed, Parallel\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric as pyg\n",
    "import zipfile, os\n",
    "import torch\n",
    "import copy\n",
    "from torch import nn\n",
    "import networkx as nx\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm.auto import trange\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.neighbors import KNeighborsRegressor,RadiusNeighborsRegressor\n",
    "\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "import torch\n",
    "import torch_geometric as pyg\n",
    "from torch_geometric.loader import DataLoader # fix\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU, Sigmoid\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import torch.optim as optim\n",
    "import joblib\n",
    "import gc\n",
    "from scipy.optimize import root_scalar\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "PATH_DATA0 = '../data/00.01'\n",
    "PATH_DATA = '../data/00.02'\n",
    "RANDOM_SEED =0\n",
    "np.random.seed(RANDOM_SEED)  \n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52d8520-ae75-4eb4-9861-d8180b66a491",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42fe8bb8-066b-4b6b-a8f6-54e8a90c992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRITERION = nn.BCEWithLogitsLoss().to(device)\n",
    "LR = 0.001\n",
    "TOLERANCE = 20\n",
    "LR_TOLERANCE= 5\n",
    "MAX_EPOCHS = 3\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe91bb8-0c7c-48d2-a847-8d49edbb98fe",
   "metadata": {},
   "source": [
    "# Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c57214d9-6e6a-4ecf-ae09-238372e64216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader_train = pyg.loader.DataLoader(\n",
    "#     pd.read_pickle(os.path.join(PATH_DATA0, 'graphs','max_prob_10_subsample_0.1','graphs_train.pkl')).tolist(),\n",
    "#     batch_size = BATCH_SIZE,shuffle = True)\n",
    "# loader_val = pyg.loader.DataLoader(\n",
    "#     pd.read_pickle(os.path.join(PATH_DATA0, 'graphs','max_prob_10_subsample_0.1','graphs_val.pkl')).tolist(),batch_size = BATCH_SIZE\n",
    "#     ,shuffle = False)\n",
    "# loader_test = pyg.loader.DataLoader(\n",
    "#     pd.read_pickle(os.path.join(PATH_DATA0, 'graphs','max_prob_10_subsample_0.1','graphs_test.pkl')).tolist(),batch_size = BATCH_SIZE\n",
    "#     ,shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "149ef375",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = DataLoader(\n",
    "    pd.read_pickle(os.path.join(PATH_DATA0, 'graphs','max_prob_10_subsample_0.1','graphs_train.pkl')).tolist(),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "loader_val = DataLoader(\n",
    "    pd.read_pickle(os.path.join(PATH_DATA0, 'graphs','max_prob_10_subsample_0.1','graphs_val.pkl')).tolist(),\n",
    "    batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n",
    "loader_test = DataLoader(\n",
    "    pd.read_pickle(os.path.join(PATH_DATA0, 'graphs','max_prob_10_subsample_0.1','graphs_test.pkl')).tolist(),\n",
    "    batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2222d194-3ee1-42b0-998b-0c76b5ca8d0c",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc509bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x: 3 node features\n",
    "# edge_index: graph connectivity\n",
    "# edge_attr: unused here\n",
    "class GCNN(nn.Module):\n",
    "    def __init__(self, num_node_features, num_edge_features, num_classes, num_layers=3, hidden_mult=1, device='cpu'):\n",
    "        super(GCNN, self).__init__()\n",
    "        self.num_node_features = num_node_features\n",
    "        self.num_edge_features = num_edge_features\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "        self.no_cuda = True if device == 'cpu' else True if self.device == 'mps' else False\n",
    "        self.hidden_mult = hidden_mult\n",
    "\n",
    "\n",
    "        # feature_dim_map = {\n",
    "        #     1: int(64 * hidden_mult),\n",
    "        #     2: int(128 * hidden_mult),\n",
    "        #     3: int(256 * hidden_mult),\n",
    "        #     4: int(512 * hidden_mult),\n",
    "        #     5: int(1024 * hidden_mult)\n",
    "        # }\n",
    "\n",
    "        # edgeconv_out_dim = 128\n",
    "        edgeconv_out_dim = self._ndim_map(hidden_mult if hidden_mult > 1 else 1)\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        # self.layers.append(\n",
    "        #     pyg.nn.EdgeConv(nn.Sequential(\n",
    "        #         nn.Linear(num_node_features * 2, 64),\n",
    "        #         nn.ReLU(),\n",
    "        #         # nn.Linear(64, 128),\n",
    "        #         nn.Linear(64, edgeconv_out_dim),\n",
    "        #         nn.ReLU()\n",
    "        #     ))\n",
    "        # )\n",
    "        # subsequent EdgeConv layers\n",
    "        prev_out_dim = edgeconv_out_dim\n",
    "        for i in range(1, num_layers + 1):\n",
    "            if i == 1 and num_layers > 1:\n",
    "                # print(\"first layer, num_layers > 1\")\n",
    "                next_out_dim = self._ndim_map(i + 1)\n",
    "                self.layers.append(\n",
    "                    pyg.nn.EdgeConv(nn.Sequential(\n",
    "                        nn.Linear(num_edge_features * 2, prev_out_dim),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(prev_out_dim, next_out_dim),\n",
    "                        nn.ReLU()\n",
    "                    ))\n",
    "                )\n",
    "                prev_out_dim = next_out_dim\n",
    "            elif i == 1 and num_layers == 1:\n",
    "                # print(\"first layer, num_layers == 1\")\n",
    "                self.layers.append(\n",
    "                    pyg.nn.EdgeConv(nn.Sequential(\n",
    "                        nn.Linear(num_edge_features * 2, prev_out_dim),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(prev_out_dim, 128),\n",
    "                        nn.ReLU()\n",
    "                    ))\n",
    "                )\n",
    "                # The output of this single layer is 128 dims\n",
    "                prev_out_dim = 128\n",
    "                edgeconv_out_dim = prev_out_dim  # keep edgeconv_out_dim for logging\n",
    "            elif i > 1 and i < num_layers:\n",
    "                # print(\"middle layer\")\n",
    "                next_out_dim = self._ndim_map(i + 1)\n",
    "                self.layers.append(\n",
    "                    pyg.nn.EdgeConv(nn.Sequential(\n",
    "                        nn.Linear(prev_out_dim * 2, prev_out_dim),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(prev_out_dim, next_out_dim),\n",
    "                        nn.ReLU()\n",
    "                    ))\n",
    "                )\n",
    "                prev_out_dim = next_out_dim\n",
    "            elif i > 1 and  i == num_layers:\n",
    "                # print(\"last layer\")\n",
    "                next_out_dim = self._ndim_map(i + 1)\n",
    "                self.layers.append(\n",
    "                    pyg.nn.EdgeConv(nn.Sequential(\n",
    "                        nn.Linear(prev_out_dim * 2, prev_out_dim),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(prev_out_dim, 128),\n",
    "                        nn.ReLU()\n",
    "                    ))\n",
    "                )\n",
    "                # update prev_out_dim to match this final layer's output\n",
    "                prev_out_dim = 128\n",
    "            else:\n",
    "                print(f\"DEBUG: i = {i}\")\n",
    "                print(\"Bad state in EdgeConv layer creation\")\n",
    "                # next_out_dim = self._ndim_map(i + 1)\n",
    "                # self.layers.append(\n",
    "                #     pyg.nn.EdgeConv(nn.Sequential(\n",
    "                #         nn.Linear(prev_out_dim, prev_out_dim),\n",
    "                #         nn.ReLU(),\n",
    "                #         nn.Linear(prev_out_dim, next_out_dim),\n",
    "                #         nn.ReLU()\n",
    "                #     ))\n",
    "                # )\n",
    "                # prev_out_dim = next_out_dim\n",
    "        # print(f\"DEBUG: edgeconv_out_dim = {edgeconv_out_dim}\")\n",
    "        # print(f\"DEBUG: prev_out_dim = {prev_out_dim}\")\n",
    "\n",
    "        # Edge-level fully connected layers\n",
    "        self.fc1 = nn.Linear(prev_out_dim * 2, 128, device=device)\n",
    "        self.fc2 = nn.Linear(128, num_classes, device=device)\n",
    "\n",
    "        # Move model to the designated device\n",
    "        self.to(device)\n",
    "\n",
    "    def _ndim_map(self, n):\n",
    "        # 1: 64\n",
    "        # 2: 128\n",
    "        # 3: 256\n",
    "        # 4: 512\n",
    "        # 5: 1024\n",
    "        # 6: 2048\n",
    "        # 7: 4096\n",
    "        if n < 1:\n",
    "            raise ValueError(\"n must be at least 1\")\n",
    "        if n % 1 != 0:\n",
    "            raise ValueError(\"n must be an integer\")\n",
    "        return 2**(5+n) * int(self.hidden_mult)\n",
    "\n",
    "    # def _init_weights(self, m):\n",
    "    #     if isinstance(m, nn.Linear):\n",
    "    #         nn.init.xavier_uniform_(m.weight)\n",
    "    #         if m.bias is not None:\n",
    "    #             nn.init.zeros_(m.bias)\n",
    "    #     elif isinstance(m, nn.Conv1d):\n",
    "    #         nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "    #         if m.bias is not None:\n",
    "    #             nn.init.zeros_(m.bias)\n",
    "    #     elif isinstance(m, nn.BatchNorm1d):\n",
    "    #         nn.init.ones_(m.weight)\n",
    "    #         nn.init.zeros_(m.bias)\n",
    "    #     elif isinstance(m, nn.LayerNorm):\n",
    "    #         nn.init.ones_(m.weight)\n",
    "    #         nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.edge_attr.to(self.device), data.edge_index.to(self.device)\n",
    "\n",
    "        # Apply EdgeConv layers to get node embeddings\n",
    "        for conv in self.layers[:self.num_layers]:\n",
    "            x = conv(x, edge_index)\n",
    "\n",
    "        # Edge-level predictions: concatenate features of each edge's endpoints\n",
    "        row, col = edge_index\n",
    "        edge_emb = torch.cat([x[row], x[col]], dim=1)\n",
    "\n",
    "        # Pass through MLP\n",
    "        edge_h = F.relu(self.fc1(edge_emb))\n",
    "        edge_out = self.fc2(edge_h)\n",
    "\n",
    "        # Return one output per edge\n",
    "        return torch.sigmoid(edge_out).squeeze(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3ee9f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x: 3 node features\n",
    "# edge_index: graph connectivity\n",
    "# edge_attr: unused here\n",
    "class DGCNN(nn.Module):\n",
    "    def __init__(self, num_node_features, num_edge_features, num_classes, num_layers=3, hidden_mult=1, k=20, device='cpu'):\n",
    "        super(DGCNN, self).__init__()\n",
    "        self.num_node_features = num_node_features\n",
    "        self.num_edge_features = num_edge_features\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "        self.no_cuda = True if device == 'cpu' else True if self.device == 'mps' else False\n",
    "        self.hidden_mult = hidden_mult\n",
    "        self.k = k\n",
    "\n",
    "        edgeconv_out_dim = self._ndim_map(hidden_mult if hidden_mult > 1 else 1)\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        prev_out_dim = edgeconv_out_dim\n",
    "        for i in range(1, num_layers + 1):\n",
    "            if i == 1 and num_layers > 1:\n",
    "                # print(\"first layer, num_layers > 1\")\n",
    "                next_out_dim = self._ndim_map(i + 1)\n",
    "                self.layers.append(\n",
    "                    pyg.nn.DynamicEdgeConv(nn.Sequential(\n",
    "                        # nn.Linear(num_edge_features * 2, prev_out_dim),\n",
    "                        nn.Linear(3 * 2, prev_out_dim),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(prev_out_dim, next_out_dim),\n",
    "                        nn.ReLU()\n",
    "                    ), self.k)  # k=20 is a common choice for DGCNN\n",
    "                )\n",
    "                prev_out_dim = next_out_dim\n",
    "            elif i == 1 and num_layers == 1:\n",
    "                # print(\"first layer, num_layers == 1\")\n",
    "                self.layers.append(\n",
    "                    pyg.nn.DynamicEdgeConv(nn.Sequential(\n",
    "                        nn.Linear(num_edge_features * 2, prev_out_dim),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(prev_out_dim, 128),\n",
    "                        nn.ReLU()\n",
    "                    ), self.k)  # k=20 is a common choice for DGCNN\n",
    "                )\n",
    "                # The output of this single layer is 128 dims\n",
    "                prev_out_dim = 128\n",
    "                edgeconv_out_dim = prev_out_dim  # keep edgeconv_out_dim for logging\n",
    "            elif i > 1 and i < num_layers:\n",
    "                # print(\"middle layer\")\n",
    "                next_out_dim = self._ndim_map(i + 1)\n",
    "                self.layers.append(\n",
    "                    pyg.nn.DynamicEdgeConv(nn.Sequential(\n",
    "                        nn.Linear(prev_out_dim * 2, prev_out_dim),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(prev_out_dim, next_out_dim),\n",
    "                        nn.ReLU()\n",
    "                    ), self.k)  # k=20 is a common choice for DGCNN\n",
    "                )\n",
    "                prev_out_dim = next_out_dim\n",
    "            elif i > 1 and  i == num_layers:\n",
    "                # print(\"last layer\")\n",
    "                next_out_dim = self._ndim_map(i + 1)\n",
    "                self.layers.append(\n",
    "                    pyg.nn.DynamicEdgeConv(nn.Sequential(\n",
    "                        nn.Linear(prev_out_dim * 2, prev_out_dim),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(prev_out_dim, 128),\n",
    "                        nn.ReLU()\n",
    "                    ), self.k)\n",
    "                )\n",
    "                # update prev_out_dim to match this final layer's output\n",
    "                prev_out_dim = 128\n",
    "            else:\n",
    "                print(f\"DEBUG: i = {i}\")\n",
    "                print(\"Bad state in EdgeConv layer creation\")\n",
    "                # next_out_dim = self._ndim_map(i + 1)\n",
    "                # self.layers.append(\n",
    "                #     pyg.nn.EdgeConv(nn.Sequential(\n",
    "                #         nn.Linear(prev_out_dim, prev_out_dim),\n",
    "                #         nn.ReLU(),\n",
    "                #         nn.Linear(prev_out_dim, next_out_dim),\n",
    "                #         nn.ReLU()\n",
    "                #     ))\n",
    "                # )\n",
    "                # prev_out_dim = next_out_dim\n",
    "        # print(f\"DEBUG: edgeconv_out_dim = {edgeconv_out_dim}\")\n",
    "        # print(f\"DEBUG: prev_out_dim = {prev_out_dim}\")\n",
    "\n",
    "        # Edge-level fully connected layers\n",
    "        self.fc1 = nn.Linear(prev_out_dim * 2, 128, device=device)\n",
    "        self.fc2 = nn.Linear(128, num_classes, device=device)\n",
    "\n",
    "        # Move model to the designated device\n",
    "        self.to(device)\n",
    "\n",
    "    def _ndim_map(self, n):\n",
    "        # 1: 64\n",
    "        # 2: 128\n",
    "        # 3: 256\n",
    "        # 4: 512\n",
    "        # 5: 1024\n",
    "        # 6: 2048\n",
    "        # 7: 4096\n",
    "        if n < 1:\n",
    "            raise ValueError(\"n must be at least 1\")\n",
    "        if n % 1 != 0:\n",
    "            raise ValueError(\"n must be an integer\")\n",
    "        return 2**(5+n) * int(self.hidden_mult)\n",
    "\n",
    "    # def _init_weights(self, m):\n",
    "    #     if isinstance(m, nn.Linear):\n",
    "    #         nn.init.xavier_uniform_(m.weight)\n",
    "    #         if m.bias is not None:\n",
    "    #             nn.init.zeros_(m.bias)\n",
    "    #     elif isinstance(m, nn.Conv1d):\n",
    "    #         nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "    #         if m.bias is not None:\n",
    "    #             nn.init.zeros_(m.bias)\n",
    "    #     elif isinstance(m, nn.BatchNorm1d):\n",
    "    #         nn.init.ones_(m.weight)\n",
    "    #         nn.init.zeros_(m.bias)\n",
    "    #     elif isinstance(m, nn.LayerNorm):\n",
    "    #         nn.init.ones_(m.weight)\n",
    "    #         nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # x, edge_index = data.edge_attr.to(self.device), data.edge_index.to(self.device)\n",
    "\n",
    "        x = data.x.to(self.device)\n",
    "        edge_index = data.edge_index.to(self.device)\n",
    "        batch = data.batch.to(self.device) \n",
    "\n",
    "\n",
    "        # Apply EdgeConv layers to get node embeddings\n",
    "        # for conv in self.layers[:self.num_layers]:\n",
    "        #     x = conv(x, edge_index)\n",
    "        for conv in self.layers:\n",
    "            x = conv(x, batch=batch)\n",
    "\n",
    "        # Edge-level predictions: concatenate features of each edge's endpoints\n",
    "        row, col = edge_index\n",
    "        edge_emb = torch.cat([x[row], x[col]], dim=1)\n",
    "\n",
    "        # Pass through MLP\n",
    "        edge_h = F.relu(self.fc1(edge_emb))\n",
    "        edge_out = self.fc2(edge_h)\n",
    "\n",
    "        # Return one output per edge\n",
    "        return torch.sigmoid(edge_out).squeeze(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e474f636-44c5-4064-b74d-2715dfe92888",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bf42440-53fd-4ca4-84de-2752fcacb1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return trainable_params\n",
    "\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    print(f\"Model loaded from {path}\")\n",
    "    return model\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch)\n",
    "            # y_nodes = batch.y.float().unsqueeze(-1)  # [num_nodes,1]\n",
    "            y_edges = batch.y.float().squeeze(1)  # [num_edges,1] TRUTH\n",
    "            # manual pooling using batch.ptr\n",
    "            ptr = batch.ptr  # shape [num_graphs+1]\n",
    "            # compute mean of y_nodes for each graph\n",
    "            # y_graph = torch.cat([\n",
    "            #     y_nodes[ptr[i]:ptr[i+1]].mean(dim=0, keepdim=True)\n",
    "            #     for i in range(ptr.size(0) - 1)\n",
    "            # ], dim=0).squeeze(-1)\n",
    "            preds.append(out)\n",
    "            actuals.append(y_edges)\n",
    "            # actuals.append(y_graph)\n",
    "        preds = torch.cat(preds, dim=0)\n",
    "        actuals = torch.cat(actuals, dim=0)\n",
    "        acc = ((torch.sigmoid(preds)>0.5)==(actuals>0.5)).float().mean().item()\n",
    "        # print([(p.item(), a.item()) for p, a in zip(preds, actuals)])\n",
    "        # print(f\"preds: {preds}, actuals: {actuals}, acc: {acc}\")\n",
    "        entropy = CRITERION(preds, actuals).item()\n",
    "    model.train()\n",
    "    return preds.cpu().numpy(), actuals.cpu().numpy(), acc, entropy\n",
    "\n",
    "def train_epoch(model, loader_train, optimizer):\n",
    "    model.train()\n",
    "    print(\"Running on \", next(model.parameters()).device)\n",
    "    train_loss = 0.0\n",
    "    for batch in tqdm(loader_train, leave=False):\n",
    "        batch = batch.to(device)\n",
    "        # Ensure key graph tensors are on the target device\n",
    "        if hasattr(batch, 'x') and isinstance(batch.x, torch.Tensor):\n",
    "            assert str(batch.x.device).startswith(str(device)), f\"batch.x on {batch.x.device}, expected {device}\"\n",
    "        if hasattr(batch, 'edge_index') and isinstance(batch.edge_index, torch.Tensor):\n",
    "            assert str(batch.edge_index.device).startswith(str(device)), f\"batch.edge_index on {batch.edge_index.device}, expected {device}\"\n",
    "        if hasattr(batch, 'edge_attr') and isinstance(batch.edge_attr, torch.Tensor):\n",
    "            assert str(batch.edge_attr.device).startswith(str(device)), f\"batch.edge_attr on {batch.edge_attr.device}, expected {device}\"\n",
    "        if hasattr(batch, 'batch') and isinstance(batch.batch, torch.Tensor):\n",
    "            assert str(batch.batch.device).startswith(str(device)), f\"batch.batch on {batch.batch.device}, expected {device}\"\n",
    "        if hasattr(batch, 'y') and isinstance(batch.y, torch.Tensor):\n",
    "            assert str(batch.y.device).startswith(str(device)), f\"batch.y on {batch.y.device}, expected {device}\"\n",
    "        optimizer.zero_grad()\n",
    "        # print(f\"batch: {batch}\")\n",
    "        out = model(batch)                # [batch_size,1]\n",
    "        # graph-level target\n",
    "        # y_nodes = batch.y.float().unsqueeze(-1)     # [num_nodes,1] WRONG?\n",
    "        y_edges = batch.y.float().squeeze(1)     # [num_edges,1] TRUTH\n",
    "        # manual pooling using batch.ptr\n",
    "        ptr = batch.ptr\n",
    "        # y_graph = torch.cat([\n",
    "        #     y_nodes[ptr[i]:ptr[i+1]].mean(dim=0, keepdim=True)\n",
    "        #     for i in range(ptr.size(0) - 1)\n",
    "        # ], dim=0).squeeze(-1)\n",
    "        # print(f\"out: {out}, y_graph: {y_graph}\")\n",
    "        # print(f\"out.shape: {out.shape}, y_graph.shape: {y_graph.shape}\")\n",
    "        # loss = CRITERION(out, y_graph)\n",
    "        loss = CRITERION(out, y_edges)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * batch.num_graphs\n",
    "    return train_loss / len(loader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ab3ce22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3207e-01, -1.9634e-02,  2.4826e-01, -6.9013e-01],\n",
       "        [-4.6413e-01, -4.6385e-02,  4.9653e-01, -6.6614e-01],\n",
       "        [-6.2136e-01, -6.2315e-02,  6.6473e-01, -6.5209e-01],\n",
       "        ...,\n",
       "        [-4.2989e-01,  5.0476e+00, -4.9280e-01,  4.4754e+00],\n",
       "        [-4.9400e-01, -1.7182e-01, -5.0646e-01, -4.8015e-01],\n",
       "        [ 6.6460e-03, -1.7567e-03,  3.7240e-03, -5.6318e-01]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loader_train.dataset\n",
    "data[0].edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3430db76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in model:  91201\n"
     ]
    }
   ],
   "source": [
    "N_LAYERS = 2\n",
    "HIDDEN_MULT = 1\n",
    "\n",
    "# Numper of parameters\n",
    "print(\"Number of parameters in model: \", count_parameters(DGCNN(3, 4, 1, N_LAYERS, HIDDEN_MULT).to(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff5c058-e13a-4203-9aff-6d8706678e06",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "70d49b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): DynamicEdgeConv(nn=Sequential(\n",
      "    (0): Linear(in_features=6, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "  ), k=20)\n",
      "  (1): DynamicEdgeConv(nn=Sequential(\n",
      "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "  ), k=20)\n",
      "  (2): DynamicEdgeConv(nn=Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "  ), k=20)\n",
      ")\n",
      "Running on  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e31e07f69f4272b45d2f69d4047044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../data/00.02/best_model_epoch_1.pth\n",
      "Epoch 1/3, Train Loss: 16.0050, Val Acc: 0.8494, Val Entropy: 0.4638\n",
      "Running on  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f233813ae8459c85ee4262111bc1df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: 14.5908, Val Acc: 0.8494, Val Entropy: 0.4638\n",
      "Running on  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4226a1a01d584606ac4515e8a72dd7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: 14.5926, Val Acc: 0.8494, Val Entropy: 0.4638\n"
     ]
    }
   ],
   "source": [
    "# Simplified training loop\n",
    "def train_model(model, loader_train, loader_val, num_epochs=MAX_EPOCHS, lr=LR):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    # for name, p in model.named_parameters():\n",
    "    #     print(f\"{name}: {p.device}\")\n",
    "    print(model.layers)\n",
    "    best_val_acc = 0.0\n",
    "    best_model = None\n",
    "    train_losses = []\n",
    "    val_accs = []\n",
    "    val_entropies = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_epoch(model, loader_train, optimizer)\n",
    "        val_preds, val_actuals, val_acc, val_entropy = evaluate(model, loader_val)\n",
    "        train_losses.append(train_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        val_entropies.append(val_entropy)\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model = copy.deepcopy(model)\n",
    "            save_model(best_model, os.path.join(PATH_DATA, f\"best_model_epoch_{epoch+1}.pth\"))\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Acc: {val_acc:.4f}, Val Entropy: {val_entropy:.4f}\")\n",
    "\n",
    "        # for name, p in model.named_parameters():\n",
    "        #     print(f\"{name}: {p.device}\")\n",
    "    return best_model, train_losses, val_accs, val_entropies\n",
    "\n",
    "def plot_training(train_losses, val_accs, val_entropies):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(val_accs, label='Val Acc')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(val_entropies, label='Val Entropy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Entropy')\n",
    "    plt.title('Validation Entropy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    print(f\"Model loaded from {path}\")\n",
    "\n",
    "def predict(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            preds = model(data)\n",
    "            all_preds.append(preds)\n",
    "    return torch.cat(all_preds, dim=0)\n",
    "\n",
    "# Run training\n",
    "model, train_losses, val_accs, val_entropies = train_model(\n",
    "    model=DGCNN(num_node_features=3, num_edge_features=4, num_classes=1, num_layers=3, hidden_mult=1, device=\"cpu\"),\n",
    "    loader_train=loader_train,\n",
    "    loader_val=loader_val,\n",
    "    num_epochs=MAX_EPOCHS,\n",
    "    lr=LR\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aabb44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: i = 1\n",
      "first layer, num_layers > 1\n",
      "DEBUG: i = 2\n",
      "last layer\n",
      "DEBUG: edgeconv_out_dim = 64\n",
      "DEBUG: prev_out_dim = 128\n",
      "Number of parameters in the model: 74817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): EdgeConv(nn=Sequential(\n",
       "    (0): Linear(in_features=6, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "  ))\n",
       "  (1): EdgeConv(nn=Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "  ))\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DGCNN(num_node_features=3, num_edge_features=4, num_classes=1, device=device, num_layers=3, hidden_mult=1)\n",
    "print(f\"Number of parameters in the model: {count_parameters(model)}\")\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2579cb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac9a06f7a294ab2be2581f5ea40dafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d499f2876fb3489eb55457cf42621d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers: 3\n",
      "Target Params: 1000000\n",
      "(1) Optimal h: 2\n",
      "Model Summary:\n",
      "--------------------------------------------------\n",
      "Model Type: DGCNN\n",
      "Number of Layers: 3\n",
      "Number of Parameters: 953985\n",
      "Device: cpu\n",
      "--------------------------------------------------\n",
      "Layer Details:\n",
      "ModuleList(\n",
      "  (0): DynamicEdgeConv(nn=Sequential(\n",
      "    (0): Linear(in_features=6, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "  ), k=20)\n",
      "  (1): DynamicEdgeConv(nn=Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "  ), k=20)\n",
      "  (2): DynamicEdgeConv(nn=Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "  ), k=20)\n",
      ")\n",
      "Epoch | Train Loss |  Val Loss |  Val Acc |  Test Acc\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fac2907d2094ff49d7372377f092246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55fc3101503744a0be42c6822b2f90cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 |    15.5158 |    0.4638 |   0.8494 |    0.8533 *\n",
      "Running on  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "746a21975fb84271bf831dc202435545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_model_summary(model):\n",
    "    print(\"Model Summary:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Model Type: {type(model).__name__}\")\n",
    "    print(f\"Number of Layers: {model.num_layers}\")\n",
    "    print(f\"Number of Parameters: {count_parameters(model)}\")\n",
    "    print(f\"Device: {model.device}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Layer Details:\")\n",
    "    print(model.layers)\n",
    "\n",
    "nom_args = (3, 4, 1)\n",
    "\n",
    "def f(n_layers, target_params):\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    print(f\"Layers: { n_layers }\")\n",
    "    print(f\"Target Params: { target_params }\")\n",
    "    # Find out the hyperparameteres yielding #params = target_params\n",
    "    def objective(h):\n",
    "        out = count_parameters(DGCNN(*nom_args, hidden_mult=int(h), num_layers=n_layers, device=device)) - target_params\n",
    "        # print(f\"Hidden Mult: {h}, Params: {out}\")\n",
    "        return out\n",
    "    \n",
    "    optimal_h = int(root_scalar(objective, bracket=[1, 4], method='bisect').root)\n",
    "    print(f\"(1) Optimal h: {optimal_h}\")\n",
    "    # optimal_h= pd.Series({optimal_h:target_params-count_parameters(DGCNN(*nom_args, hidden_mult=optimal_h, num_layers=n_layers)),\n",
    "    #             optimal_h-1:target_params-count_parameters(DGCNN(*nom_args, hidden_mult=optimal_h-1, num_layers=n_layers)),\n",
    "    #             optimal_h+1:target_params-count_parameters(DGCNN(*nom_args, hidden_mult=optimal_h+1, num_layers=n_layers))}).abs().idxmin()\n",
    "    # print(f\"(2) Optimal h: {optimal_h}\")\n",
    "    \n",
    "    # model = DGCNN(optimal_h,n_layers).to(device) \n",
    "    # model = InteractionNetwork(optimal_h,n_layers).to(device)\n",
    "    model = DGCNN(*nom_args, hidden_mult=optimal_h, num_layers=n_layers, device=device)\n",
    "    print_model_summary(model)\n",
    "    lr = LR\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve, epochs_no_improve2 = 0,0\n",
    "    best_model_state = None\n",
    "    stats = []\n",
    "    best = None\n",
    "    # Print header once\n",
    "    print(f\"{'Epoch':>5} | {'Train Loss':>10} | {'Val Loss':>9} | {'Val Acc':>8} | {'Test Acc':>9}\")\n",
    "    print(\"-\" * 50)\n",
    "    for epoch in trange(MAX_EPOCHS):\n",
    "        train_loss = train_epoch(model, loader_train, optimizer)   \n",
    "        preds_val, actuals_val, acc_val, val_loss = evaluate(model,loader_val)\n",
    "        preds_test, actuals_test, acc_test, test_loss = evaluate(model,loader_test)\n",
    "        \n",
    "        stats.append({'train_loss':train_loss, 'val_loss':val_loss, 'acc_val':acc_val, 'acc_test':acc_test})\n",
    "        if val_loss < best_val_loss: \n",
    "            print(f\"{epoch+1:5d} | {train_loss:10.4f} | {val_loss:9.4f} | {acc_val:8.4f} | {acc_test:9.4f} *\")\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            epochs_no_improve2 = 0\n",
    "            best = {'model_state': {k: v.cpu() for k, v in model.state_dict().items()},\n",
    "                    'preds_test':preds_test, 'preds_val':preds_val}        \n",
    "        else:\n",
    "            print(f\"{epoch+1:5d} | {train_loss:10.4f} | {val_loss:9.4f} | {acc_val:8.4f} | {acc_test:9.4f}\")\n",
    "            epochs_no_improve += 1\n",
    "            epochs_no_improve2 += 1\n",
    "\n",
    "        if epochs_no_improve >= TOLERANCE:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "        if epochs_no_improve2 >= LR_TOLERANCE:\n",
    "            if lr >=1.0e-8:\n",
    "                lr/=10\n",
    "            print(f\"LR reduction to {lr}\")\n",
    "    best['stats'] = stats\n",
    "    os.makedirs(PATH_DATA, exist_ok=True)\n",
    "    joblib.dump(best, os.path.join(PATH_DATA, f\"{n_layers}_{target_params}.pkl\"))\n",
    "    \n",
    "    stats = pd.DataFrame(stats)\n",
    "    stats[['train_loss','val_loss']].plot(figsize = (15,4))\n",
    "    plt.show()\n",
    "    stats[['acc_val','acc_test']].plot(figsize = (15,4))\n",
    "    plt.show()\n",
    "    del model\n",
    "    del train_loss\n",
    "    del optimizer\n",
    "\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "Parallel(n_jobs=1)(delayed(f)(n_layers, target_params)\n",
    "                    for n_layers in tqdm([3,4])\n",
    "                    # for target_params in tqdm([100_000, 500_000, 10_000]))\n",
    "                    for target_params in tqdm([1_000_000, 100_000, 500_000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7e8cf251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: i = 1\n",
      "first layer, num_layers > 1\n",
      "DEBUG: i = 2\n",
      "last layer\n",
      "DEBUG: edgeconv_out_dim = 64\n",
      "DEBUG: prev_out_dim = 128\n",
      "Params: 74817\n",
      "DEBUG: i = 1\n",
      "first layer, num_layers == 1\n",
      "DEBUG: edgeconv_out_dim = 128\n",
      "DEBUG: prev_out_dim = 128\n",
      "Hidden Mult: 1, Params: 24409\n",
      "DEBUG: i = 1\n",
      "first layer, num_layers > 1\n",
      "DEBUG: i = 2\n",
      "last layer\n",
      "DEBUG: edgeconv_out_dim = 64\n",
      "DEBUG: prev_out_dim = 128\n",
      "Params: 74817\n",
      "DEBUG: i = 1\n",
      "first layer, num_layers == 1\n",
      "DEBUG: edgeconv_out_dim = 128\n",
      "DEBUG: prev_out_dim = 128\n",
      "Hidden Mult: 1, Params: 24409\n",
      "DEBUG: i = 1\n",
      "first layer, num_layers > 1\n",
      "DEBUG: i = 2\n",
      "last layer\n",
      "DEBUG: edgeconv_out_dim = 64\n",
      "DEBUG: prev_out_dim = 128\n",
      "Params: 74817\n",
      "DEBUG: i = 1\n",
      "first layer, num_layers == 1\n",
      "DEBUG: edgeconv_out_dim = 128\n",
      "DEBUG: prev_out_dim = 128\n",
      "Hidden Mult: 1, Params: 24409\n",
      "DEBUG: i = 1\n",
      "first layer, num_layers > 1\n",
      "DEBUG: i = 2\n",
      "last layer\n",
      "DEBUG: edgeconv_out_dim = 64\n",
      "DEBUG: prev_out_dim = 128\n",
      "Params: 74817\n",
      "DEBUG: i = 1\n",
      "first layer, num_layers == 1\n",
      "DEBUG: edgeconv_out_dim = 128\n",
      "DEBUG: prev_out_dim = 128\n",
      "Hidden Mult: 1, Params: 24409\n",
      "Hidden Mult: 1, Params: 24409\n",
      "DEBUG: i = 1\n",
      "first layer, num_layers > 1\n",
      "DEBUG: i = 2\n",
      "last layer\n",
      "DEBUG: edgeconv_out_dim = 64\n",
      "DEBUG: prev_out_dim = 128\n",
      "Params: 74817\n",
      "DEBUG: i = 1\n",
      "first layer, num_layers == 1\n",
      "DEBUG: edgeconv_out_dim = 128\n",
      "DEBUG: prev_out_dim = 128\n",
      "Hidden Mult: 1.0, Params: 24409\n",
      "DEBUG: i = 1\n",
      "first layer, num_layers > 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, torch.memory_format memory_format = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHidden Mult: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_h\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobjective(_h)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHidden Mult: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_h\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobjective(_h)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m optimal_h = \u001b[43mroot_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbracket\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbisect\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m.root\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gnn-class/lib/python3.11/site-packages/scipy/optimize/_root_scalar.py:286\u001b[39m, in \u001b[36mroot_scalar\u001b[39m\u001b[34m(f, args, method, bracket, fprime, fprime2, x0, x1, xtol, rtol, maxiter, options)\u001b[39m\n\u001b[32m    284\u001b[39m a, b = bracket[:\u001b[32m2\u001b[39m]\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     r, sol = \u001b[43mmethodc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    288\u001b[39m     \u001b[38;5;66;03m# gh-17622 fixed some bugs in low-level solvers by raising an error\u001b[39;00m\n\u001b[32m    289\u001b[39m     \u001b[38;5;66;03m# (rather than returning incorrect results) when the callable\u001b[39;00m\n\u001b[32m    290\u001b[39m     \u001b[38;5;66;03m# returns a NaN. It did so by wrapping the callable rather than\u001b[39;00m\n\u001b[32m    291\u001b[39m     \u001b[38;5;66;03m# modifying compiled code, so the iteration count is not available.\u001b[39;00m\n\u001b[32m    292\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gnn-class/lib/python3.11/site-packages/scipy/optimize/_zeros_py.py:577\u001b[39m, in \u001b[36mbisect\u001b[39m\u001b[34m(f, a, b, args, xtol, rtol, maxiter, full_output, disp)\u001b[39m\n\u001b[32m    575\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mrtol too small (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrtol\u001b[38;5;132;01m:\u001b[39;00m\u001b[33mg\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m < \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_rtol\u001b[38;5;132;01m:\u001b[39;00m\u001b[33mg\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    576\u001b[39m f = _wrap_nan_raise(f)\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m r = \u001b[43m_zeros\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_bisect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results_c(full_output, r, \u001b[33m\"\u001b[39m\u001b[33mbisect\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gnn-class/lib/python3.11/site-packages/scipy/optimize/_zeros_py.py:94\u001b[39m, in \u001b[36m_wrap_nan_raise.<locals>.f_raise\u001b[39m\u001b[34m(x, *args)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mf_raise\u001b[39m(x, *args):\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     fx = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     f_raise._function_calls += \u001b[32m1\u001b[39m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m np.isnan(fx):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(h)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mobjective\u001b[39m(h):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mParams: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount_parameters(\u001b[43mDGCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mnom_args\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mhidden_mult\u001b[49m\u001b[43m=\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m     out = count_parameters(DGCNN(*nom_args, hidden_mult=h, num_layers=\u001b[32m1\u001b[39m, device=device)) - \u001b[32m1_000\u001b[39m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHidden Mult: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mDGCNN.__init__\u001b[39m\u001b[34m(self, num_node_features, num_edge_features, num_classes, num_layers, hidden_mult, device)\u001b[39m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mfirst layer, num_layers > 1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     44\u001b[39m     next_out_dim = \u001b[38;5;28mself\u001b[39m._ndim_map(i + \u001b[32m1\u001b[39m)\n\u001b[32m     45\u001b[39m     \u001b[38;5;28mself\u001b[39m.layers.append(\n\u001b[32m     46\u001b[39m         pyg.nn.EdgeConv(nn.Sequential(\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m             \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_node_features\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_out_dim\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     48\u001b[39m             nn.ReLU(),\n\u001b[32m     49\u001b[39m             nn.Linear(prev_out_dim, next_out_dim),\n\u001b[32m     50\u001b[39m             nn.ReLU()\n\u001b[32m     51\u001b[39m         ))\n\u001b[32m     52\u001b[39m     )\n\u001b[32m     53\u001b[39m     prev_out_dim = next_out_dim\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m i == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m num_layers == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gnn-class/lib/python3.11/site-packages/torch/nn/modules/linear.py:106\u001b[39m, in \u001b[36mLinear.__init__\u001b[39m\u001b[34m(self, in_features, out_features, bias, device, dtype)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28mself\u001b[39m.in_features = in_features\n\u001b[32m    104\u001b[39m \u001b[38;5;28mself\u001b[39m.out_features = out_features\n\u001b[32m    105\u001b[39m \u001b[38;5;28mself\u001b[39m.weight = Parameter(\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m )\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[32m    109\u001b[39m     \u001b[38;5;28mself\u001b[39m.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
      "\u001b[31mTypeError\u001b[39m: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, torch.memory_format memory_format = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n"
     ]
    }
   ],
   "source": [
    "def objective(h):\n",
    "    print(f\"Params: {count_parameters(DGCNN(*nom_args, hidden_mult=h, num_layers=2, device=device))}\")\n",
    "    out = count_parameters(DGCNN(*nom_args, hidden_mult=h, num_layers=1, device=device)) - 1_000\n",
    "    print(f\"Hidden Mult: {h}, Params: {out}\")\n",
    "    return out\n",
    "\n",
    "\n",
    "_h = 1 # init\n",
    "step = 0.1\n",
    "if objective(_h) < 0 and _h >= 1:\n",
    "    while objective(_h) > 0:\n",
    "        _h -= step if _h > 1 else 0\n",
    "        print(f\"Hidden Mult: {_h}, Params: {objective(_h)}\")\n",
    "elif objective(_h) > 0:\n",
    "    while objective(_h) < 0:\n",
    "        _h += step\n",
    "        print(f\"Hidden Mult: {_h}, Params: {objective(_h)}\")\n",
    "print(f\"Hidden Mult: {_h}, Params: {objective(_h)}\")\n",
    "\n",
    "optimal_h = root_scalar(objective, bracket=[1, 10], method='bisect').root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "de2ee8b9-8fb9-46cd-832a-25d4d9b091a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9121eb19a14c9e9734a31edd9e980b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ffcaecb91264c138c5cd05590d84e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 68\u001b[39m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available():\n\u001b[32m     66\u001b[39m         torch.cuda.empty_cache()\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m                    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn_layers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m                    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarget_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1_000_000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m100_000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m                                               \u001b[49m\u001b[32;43m500_000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gnn-class/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1916\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gnn-class/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1849\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mf\u001b[39m\u001b[34m(n_layers, target_params)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mobjective\u001b[39m(h):\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m count_parameters(InteractionNetwork(\u001b[38;5;28mint\u001b[39m(h),n_layers)) - target_params\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m optimal_h = \u001b[38;5;28mint\u001b[39m(\u001b[43mroot_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbracket\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m50000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbisect\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m.root)\n\u001b[32m     10\u001b[39m optimal_h= pd.Series({optimal_h:target_params-count_parameters(InteractionNetwork(optimal_h, n_layers)),\n\u001b[32m     11\u001b[39m             optimal_h-\u001b[32m1\u001b[39m:target_params-count_parameters(InteractionNetwork(optimal_h-\u001b[32m1\u001b[39m,n_layers)),\n\u001b[32m     12\u001b[39m             optimal_h+\u001b[32m1\u001b[39m:target_params-count_parameters(InteractionNetwork(optimal_h+\u001b[32m1\u001b[39m,n_layers))}).abs().idxmin()\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# model = InteractionNetwork(optimal_h,n_layers).to(device)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gnn-class/lib/python3.11/site-packages/scipy/optimize/_root_scalar.py:286\u001b[39m, in \u001b[36mroot_scalar\u001b[39m\u001b[34m(f, args, method, bracket, fprime, fprime2, x0, x1, xtol, rtol, maxiter, options)\u001b[39m\n\u001b[32m    284\u001b[39m a, b = bracket[:\u001b[32m2\u001b[39m]\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     r, sol = \u001b[43mmethodc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    288\u001b[39m     \u001b[38;5;66;03m# gh-17622 fixed some bugs in low-level solvers by raising an error\u001b[39;00m\n\u001b[32m    289\u001b[39m     \u001b[38;5;66;03m# (rather than returning incorrect results) when the callable\u001b[39;00m\n\u001b[32m    290\u001b[39m     \u001b[38;5;66;03m# returns a NaN. It did so by wrapping the callable rather than\u001b[39;00m\n\u001b[32m    291\u001b[39m     \u001b[38;5;66;03m# modifying compiled code, so the iteration count is not available.\u001b[39;00m\n\u001b[32m    292\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_x\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gnn-class/lib/python3.11/site-packages/scipy/optimize/_zeros_py.py:577\u001b[39m, in \u001b[36mbisect\u001b[39m\u001b[34m(f, a, b, args, xtol, rtol, maxiter, full_output, disp)\u001b[39m\n\u001b[32m    575\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mrtol too small (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrtol\u001b[38;5;132;01m:\u001b[39;00m\u001b[33mg\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m < \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_rtol\u001b[38;5;132;01m:\u001b[39;00m\u001b[33mg\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    576\u001b[39m f = _wrap_nan_raise(f)\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m r = \u001b[43m_zeros\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_bisect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results_c(full_output, r, \u001b[33m\"\u001b[39m\u001b[33mbisect\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gnn-class/lib/python3.11/site-packages/scipy/optimize/_zeros_py.py:94\u001b[39m, in \u001b[36m_wrap_nan_raise.<locals>.f_raise\u001b[39m\u001b[34m(x, *args)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mf_raise\u001b[39m(x, *args):\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     fx = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     f_raise._function_calls += \u001b[32m1\u001b[39m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m np.isnan(fx):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mf.<locals>.objective\u001b[39m\u001b[34m(h)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mobjective\u001b[39m(h):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m count_parameters(\u001b[43mInteractionNetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_layers\u001b[49m\u001b[43m)\u001b[49m) - target_params\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mInteractionNetwork.__init__\u001b[39m\u001b[34m(self, hidden_size, n_layers)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_size, n_layers):\n\u001b[32m     37\u001b[39m     \u001b[38;5;28msuper\u001b[39m(InteractionNetwork, \u001b[38;5;28mself\u001b[39m).\u001b[34m__init__\u001b[39m(aggr=\u001b[33m'\u001b[39m\u001b[33madd\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m     38\u001b[39m                                              flow=\u001b[33m'\u001b[39m\u001b[33msource_to_target\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28mself\u001b[39m.R1 = \u001b[43mRelationalModel\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28mself\u001b[39m.O = ObjectModel(\u001b[32m7\u001b[39m, \u001b[32m3\u001b[39m, hidden_size, n_layers)\n\u001b[32m     41\u001b[39m     \u001b[38;5;28mself\u001b[39m.R2 = RelationalModel(\u001b[32m10\u001b[39m, \u001b[32m1\u001b[39m, hidden_size, n_layers)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mRelationalModel.__init__\u001b[39m\u001b[34m(self, input_size, output_size, hidden_size, n_layers)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_layers>=\u001b[32m2\u001b[39m:\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_layers - \u001b[32m1\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m         layers.append(\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     10\u001b[39m         layers.append(nn.ReLU())\n\u001b[32m     12\u001b[39m layers.append(nn.Linear(hidden_size, output_size))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gnn-class/lib/python3.11/site-packages/torch/nn/modules/linear.py:112\u001b[39m, in \u001b[36mLinear.__init__\u001b[39m\u001b[34m(self, in_features, out_features, bias, device, dtype)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    111\u001b[39m     \u001b[38;5;28mself\u001b[39m.register_parameter(\u001b[33m\"\u001b[39m\u001b[33mbias\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gnn-class/lib/python3.11/site-packages/torch/nn/modules/linear.py:118\u001b[39m, in \u001b[36mLinear.reset_parameters\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreset_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    115\u001b[39m     \u001b[38;5;66;03m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001b[39;00m\n\u001b[32m    116\u001b[39m     \u001b[38;5;66;03m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[39;00m\n\u001b[32m    117\u001b[39m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/57109\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     \u001b[43minit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkaiming_uniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmath\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    120\u001b[39m         fan_in, _ = init._calculate_fan_in_and_fan_out(\u001b[38;5;28mself\u001b[39m.weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gnn-class/lib/python3.11/site-packages/torch/nn/init.py:518\u001b[39m, in \u001b[36mkaiming_uniform_\u001b[39m\u001b[34m(tensor, a, mode, nonlinearity, generator)\u001b[39m\n\u001b[32m    516\u001b[39m bound = math.sqrt(\u001b[32m3.0\u001b[39m) * std  \u001b[38;5;66;03m# Calculate uniform bounds from standard deviation\u001b[39;00m\n\u001b[32m    517\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m518\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43muniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def f(n_layers,target_params):\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    print(n_layers, target_params)\n",
    "    # Find out the hyperparameteres yielding #params = target_params\n",
    "    def objective(h):\n",
    "        return count_parameters(InteractionNetwork(int(h),n_layers)) - target_params\n",
    "    \n",
    "    optimal_h = int(root_scalar(objective, bracket=[1, 50000], method='bisect').root)\n",
    "    print(f\"(1) Optimal h: {optimal_h}\")\n",
    "\n",
    "    optimal_h= pd.Series({optimal_h:target_params-count_parameters(InteractionNetwork(optimal_h, n_layers)),\n",
    "                optimal_h-1:target_params-count_parameters(InteractionNetwork(optimal_h-1,n_layers)),\n",
    "                optimal_h+1:target_params-count_parameters(InteractionNetwork(optimal_h+1,n_layers))}).abs().idxmin()\n",
    "    print(f\"(2) Optimal h: {optimal_h}\")\n",
    "    \n",
    "    # model = InteractionNetwork(optimal_h,n_layers).to(device)\n",
    "    model = DGCNN(3, 4, 1).to(device)\n",
    "    lr = LR\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve, epochs_no_improve2 = 0,0\n",
    "    best_model_state = None\n",
    "    stats = []\n",
    "    best = None\n",
    "    # Print header once\n",
    "    print(f\"{'Epoch':>5} | {'Train Loss':>10} | {'Val Loss':>9} | {'Val Acc':>8} | {'Test Acc':>9}\")\n",
    "    print(\"-\" * 50)\n",
    "    for epoch in trange(MAX_EPOCHS):\n",
    "        train_loss = train_epoch(model, loader_train, optimizer)   \n",
    "        preds_val, actuals_val, acc_val, val_loss = evaluate(model,loader_val)\n",
    "        preds_test, actuals_test, acc_test, test_loss = evaluate(model,loader_test)\n",
    "        \n",
    "        stats.append({'train_loss':train_loss, 'val_loss':val_loss, 'acc_val':acc_val, 'acc_test':acc_test})\n",
    "        if val_loss < best_val_loss: \n",
    "            print(f\"{epoch+1:5d} | {train_loss:10.4f} | {val_loss:9.4f} | {acc_val:8.4f} | {acc_test:9.4f} *\")\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            epochs_no_improve2 = 0\n",
    "            best = {'model_state': {k: v.cpu() for k, v in model.state_dict().items()},\n",
    "                    'preds_test':preds_test, 'preds_val':preds_val}        \n",
    "        else:\n",
    "            print(f\"{epoch+1:5d} | {train_loss:10.4f} | {val_loss:9.4f} | {acc_val:8.4f} | {acc_test:9.4f}\")\n",
    "            epochs_no_improve += 1\n",
    "            epochs_no_improve2 += 1\n",
    "\n",
    "        if epochs_no_improve >= TOLERANCE:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "        if epochs_no_improve2 >= LR_TOLERANCE:\n",
    "            if lr >=1.0e-8:\n",
    "                lr/=10\n",
    "            print(f\"LR reduction to {lr}\")\n",
    "    best['stats'] = stats\n",
    "    os.makedirs(PATH_DATA, exist_ok=True)\n",
    "    joblib.dump(best, os.path.join(PATH_DATA, f\"{n_layers}_{target_params}.pkl\"))\n",
    "    \n",
    "    stats = pd.DataFrame(stats)\n",
    "    stats[['train_loss','val_loss']].plot(figsize = (15,4))\n",
    "    plt.show()\n",
    "    stats[['acc_val','acc_test']].plot(figsize = (15,4))\n",
    "    plt.show()\n",
    "    del model\n",
    "    del train_loss\n",
    "    del optimizer\n",
    "\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "Parallel(n_jobs=1)(delayed(f)(n_layers,target_params)\n",
    "                    for n_layers in tqdm([2,3,4])\n",
    "                    for target_params in tqdm([1_000_000,100_000,\n",
    "                                               500_000,]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e401f1-823e-4422-8908-775d77c471f8",
   "metadata": {},
   "source": [
    "# Summary of the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ab51456-0db4-4a57-b2f9-e5e37bb9d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_pickle(os.path.join(PATH_DATA0, 'graphs','max_prob_10_subsample_0.1','graphs_val.pkl'))\n",
    "test = pd.read_pickle(os.path.join(PATH_DATA0, 'graphs','max_prob_10_subsample_0.1','graphs_test.pkl'))\n",
    "val_y = torch.cat([i.y for i in val.values]).numpy()\n",
    "test_y = torch.cat([i.y for i in test.values]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9534902e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: x_pool shape before fc1 = torch.Size([32, 128])\n",
      "DEBUG: x_out shape = torch.Size([32, 1])\n",
      "tensor([[0.3406],\n",
      "        [0.3448],\n",
      "        [0.3389],\n",
      "        [0.3434],\n",
      "        [0.3434],\n",
      "        [0.3406],\n",
      "        [0.3394],\n",
      "        [0.3444],\n",
      "        [0.3404],\n",
      "        [0.3401],\n",
      "        [0.3415],\n",
      "        [0.3432],\n",
      "        [0.3387],\n",
      "        [0.3406],\n",
      "        [0.3458],\n",
      "        [0.3404],\n",
      "        [0.3403],\n",
      "        [0.3433],\n",
      "        [0.3371],\n",
      "        [0.3428],\n",
      "        [0.3411],\n",
      "        [0.3404],\n",
      "        [0.3416],\n",
      "        [0.3416],\n",
      "        [0.3391],\n",
      "        [0.3419],\n",
      "        [0.3398],\n",
      "        [0.3416],\n",
      "        [0.3429],\n",
      "        [0.3381],\n",
      "        [0.3400],\n",
      "        [0.3418]], device='mps:0', grad_fn=<LinearBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val0 = next(iter(loader_val))\n",
    "preds = model(val0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cedd0134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1044834, 1])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val0.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acdc9319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: x_pool shape before fc1 = torch.Size([32, 128])\n",
      "DEBUG: x_out shape = torch.Size([32, 1])\n",
      "tensor([[0.3429],\n",
      "        [0.3392],\n",
      "        [0.3415],\n",
      "        [0.3425],\n",
      "        [0.3396],\n",
      "        [0.3408],\n",
      "        [0.3416],\n",
      "        [0.3416],\n",
      "        [0.3435],\n",
      "        [0.3417],\n",
      "        [0.3419],\n",
      "        [0.3453],\n",
      "        [0.3422],\n",
      "        [0.3422],\n",
      "        [0.3385],\n",
      "        [0.3410],\n",
      "        [0.3353],\n",
      "        [0.3396],\n",
      "        [0.3411],\n",
      "        [0.3391],\n",
      "        [0.3394],\n",
      "        [0.3378],\n",
      "        [0.3404],\n",
      "        [0.3425],\n",
      "        [0.3424],\n",
      "        [0.3457],\n",
      "        [0.3419],\n",
      "        [0.3394],\n",
      "        [0.3400],\n",
      "        [0.3399],\n",
      "        [0.3399],\n",
      "        [0.3360]], device='mps:0')\n",
      "DEBUG: x_pool shape before fc1 = torch.Size([32, 128])\n",
      "DEBUG: x_out shape = torch.Size([32, 1])\n",
      "tensor([[0.3424],\n",
      "        [0.3379],\n",
      "        [0.3379],\n",
      "        [0.3374],\n",
      "        [0.3404],\n",
      "        [0.3425],\n",
      "        [0.3387],\n",
      "        [0.3406],\n",
      "        [0.3386],\n",
      "        [0.3364],\n",
      "        [0.3426],\n",
      "        [0.3398],\n",
      "        [0.3378],\n",
      "        [0.3405],\n",
      "        [0.3405],\n",
      "        [0.3398],\n",
      "        [0.3415],\n",
      "        [0.3414],\n",
      "        [0.3391],\n",
      "        [0.3414],\n",
      "        [0.3414],\n",
      "        [0.3388],\n",
      "        [0.3509],\n",
      "        [0.3391],\n",
      "        [0.3480],\n",
      "        [0.3448],\n",
      "        [0.3428],\n",
      "        [0.3403],\n",
      "        [0.3393],\n",
      "        [0.3399],\n",
      "        [0.3384],\n",
      "        [0.3421]], device='mps:0')\n",
      "DEBUG: x_pool shape before fc1 = torch.Size([32, 128])\n",
      "DEBUG: x_out shape = torch.Size([32, 1])\n",
      "tensor([[0.3402],\n",
      "        [0.3457],\n",
      "        [0.3410],\n",
      "        [0.3462],\n",
      "        [0.3419],\n",
      "        [0.3404],\n",
      "        [0.3385],\n",
      "        [0.3432],\n",
      "        [0.3422],\n",
      "        [0.3432],\n",
      "        [0.3388],\n",
      "        [0.3390],\n",
      "        [0.3372],\n",
      "        [0.3415],\n",
      "        [0.3430],\n",
      "        [0.3430],\n",
      "        [0.3401],\n",
      "        [0.3413],\n",
      "        [0.3419],\n",
      "        [0.3398],\n",
      "        [0.3400],\n",
      "        [0.3419],\n",
      "        [0.3391],\n",
      "        [0.3404],\n",
      "        [0.3444],\n",
      "        [0.3452],\n",
      "        [0.3432],\n",
      "        [0.3452],\n",
      "        [0.3385],\n",
      "        [0.3439],\n",
      "        [0.3438],\n",
      "        [0.3414]], device='mps:0')\n",
      "DEBUG: x_pool shape before fc1 = torch.Size([32, 128])\n",
      "DEBUG: x_out shape = torch.Size([32, 1])\n",
      "tensor([[0.3426],\n",
      "        [0.3455],\n",
      "        [0.3412],\n",
      "        [0.3372],\n",
      "        [0.3406],\n",
      "        [0.3410],\n",
      "        [0.3417],\n",
      "        [0.3415],\n",
      "        [0.3388],\n",
      "        [0.3373],\n",
      "        [0.3406],\n",
      "        [0.3389],\n",
      "        [0.3359],\n",
      "        [0.3424],\n",
      "        [0.3434],\n",
      "        [0.3429],\n",
      "        [0.3396],\n",
      "        [0.3402],\n",
      "        [0.3433],\n",
      "        [0.3385],\n",
      "        [0.3427],\n",
      "        [0.3428],\n",
      "        [0.3383],\n",
      "        [0.3397],\n",
      "        [0.3397],\n",
      "        [0.3377],\n",
      "        [0.3391],\n",
      "        [0.3411],\n",
      "        [0.3398],\n",
      "        [0.3427],\n",
      "        [0.3415],\n",
      "        [0.3385]], device='mps:0')\n",
      "DEBUG: x_pool shape before fc1 = torch.Size([32, 128])\n",
      "DEBUG: x_out shape = torch.Size([32, 1])\n",
      "tensor([[0.3395],\n",
      "        [0.3378],\n",
      "        [0.3388],\n",
      "        [0.3405],\n",
      "        [0.3404],\n",
      "        [0.3405],\n",
      "        [0.3415],\n",
      "        [0.3413],\n",
      "        [0.3384],\n",
      "        [0.3393],\n",
      "        [0.3404],\n",
      "        [0.3404],\n",
      "        [0.3381],\n",
      "        [0.3404],\n",
      "        [0.3437],\n",
      "        [0.3437],\n",
      "        [0.3438],\n",
      "        [0.3410],\n",
      "        [0.3427],\n",
      "        [0.3427],\n",
      "        [0.3390],\n",
      "        [0.3430],\n",
      "        [0.3402],\n",
      "        [0.3451],\n",
      "        [0.3436],\n",
      "        [0.3362],\n",
      "        [0.3412],\n",
      "        [0.3476],\n",
      "        [0.3396],\n",
      "        [0.3407],\n",
      "        [0.3426],\n",
      "        [0.3428]], device='mps:0')\n",
      "DEBUG: x_pool shape before fc1 = torch.Size([17, 128])\n",
      "DEBUG: x_out shape = torch.Size([17, 1])\n",
      "tensor([[0.3358],\n",
      "        [0.3408],\n",
      "        [0.3406],\n",
      "        [0.3426],\n",
      "        [0.3413],\n",
      "        [0.3420],\n",
      "        [0.3491],\n",
      "        [0.3435],\n",
      "        [0.3417],\n",
      "        [0.3404],\n",
      "        [0.3388],\n",
      "        [0.3390],\n",
      "        [0.3397],\n",
      "        [0.3395],\n",
      "        [0.3354],\n",
      "        [0.3430],\n",
      "        [0.3490]], device='mps:0')\n",
      "DEBUG: x_pool shape before fc1 = torch.Size([32, 128])\n",
      "DEBUG: x_out shape = torch.Size([32, 1])\n",
      "tensor([[0.3406],\n",
      "        [0.3448],\n",
      "        [0.3389],\n",
      "        [0.3434],\n",
      "        [0.3434],\n",
      "        [0.3406],\n",
      "        [0.3394],\n",
      "        [0.3444],\n",
      "        [0.3404],\n",
      "        [0.3401],\n",
      "        [0.3415],\n",
      "        [0.3432],\n",
      "        [0.3387],\n",
      "        [0.3406],\n",
      "        [0.3458],\n",
      "        [0.3404],\n",
      "        [0.3403],\n",
      "        [0.3433],\n",
      "        [0.3371],\n",
      "        [0.3428],\n",
      "        [0.3411],\n",
      "        [0.3404],\n",
      "        [0.3416],\n",
      "        [0.3416],\n",
      "        [0.3391],\n",
      "        [0.3419],\n",
      "        [0.3398],\n",
      "        [0.3416],\n",
      "        [0.3429],\n",
      "        [0.3381],\n",
      "        [0.3400],\n",
      "        [0.3418]], device='mps:0')\n",
      "DEBUG: x_pool shape before fc1 = torch.Size([32, 128])\n",
      "DEBUG: x_out shape = torch.Size([32, 1])\n",
      "tensor([[0.3414],\n",
      "        [0.3414],\n",
      "        [0.3372],\n",
      "        [0.3397],\n",
      "        [0.3408],\n",
      "        [0.3430],\n",
      "        [0.3383],\n",
      "        [0.3434],\n",
      "        [0.3412],\n",
      "        [0.3411],\n",
      "        [0.3397],\n",
      "        [0.3390],\n",
      "        [0.3389],\n",
      "        [0.3381],\n",
      "        [0.3453],\n",
      "        [0.3423],\n",
      "        [0.3404],\n",
      "        [0.3453],\n",
      "        [0.3402],\n",
      "        [0.3416],\n",
      "        [0.3360],\n",
      "        [0.3417],\n",
      "        [0.3391],\n",
      "        [0.3362],\n",
      "        [0.3444],\n",
      "        [0.3358],\n",
      "        [0.3398],\n",
      "        [0.3405],\n",
      "        [0.3440],\n",
      "        [0.3464],\n",
      "        [0.3399],\n",
      "        [0.3389]], device='mps:0')\n",
      "DEBUG: x_pool shape before fc1 = torch.Size([32, 128])\n",
      "DEBUG: x_out shape = torch.Size([32, 1])\n",
      "tensor([[0.3395],\n",
      "        [0.3410],\n",
      "        [0.3380],\n",
      "        [0.3415],\n",
      "        [0.3405],\n",
      "        [0.3390],\n",
      "        [0.3444],\n",
      "        [0.3380],\n",
      "        [0.3421],\n",
      "        [0.3378],\n",
      "        [0.3422],\n",
      "        [0.3448],\n",
      "        [0.3409],\n",
      "        [0.3400],\n",
      "        [0.3392],\n",
      "        [0.3437],\n",
      "        [0.3413],\n",
      "        [0.3391],\n",
      "        [0.3398],\n",
      "        [0.3415],\n",
      "        [0.3386],\n",
      "        [0.3420],\n",
      "        [0.3421],\n",
      "        [0.3381],\n",
      "        [0.3406],\n",
      "        [0.3390],\n",
      "        [0.3394],\n",
      "        [0.3410],\n",
      "        [0.3450],\n",
      "        [0.3397],\n",
      "        [0.3416],\n",
      "        [0.3427]], device='mps:0')\n",
      "DEBUG: x_pool shape before fc1 = torch.Size([32, 128])\n",
      "DEBUG: x_out shape = torch.Size([32, 1])\n",
      "tensor([[0.3371],\n",
      "        [0.3424],\n",
      "        [0.3409],\n",
      "        [0.3397],\n",
      "        [0.3385],\n",
      "        [0.3404],\n",
      "        [0.3409],\n",
      "        [0.3425],\n",
      "        [0.3397],\n",
      "        [0.3388],\n",
      "        [0.3437],\n",
      "        [0.3433],\n",
      "        [0.3428],\n",
      "        [0.3387],\n",
      "        [0.3416],\n",
      "        [0.3402],\n",
      "        [0.3418],\n",
      "        [0.3412],\n",
      "        [0.3399],\n",
      "        [0.3422],\n",
      "        [0.3417],\n",
      "        [0.3387],\n",
      "        [0.3402],\n",
      "        [0.3426],\n",
      "        [0.3366],\n",
      "        [0.3386],\n",
      "        [0.3410],\n",
      "        [0.3404],\n",
      "        [0.3418],\n",
      "        [0.3398],\n",
      "        [0.3330],\n",
      "        [0.3420]], device='mps:0')\n",
      "DEBUG: x_pool shape before fc1 = torch.Size([13, 128])\n",
      "DEBUG: x_out shape = torch.Size([13, 1])\n",
      "tensor([[0.3474],\n",
      "        [0.3410],\n",
      "        [0.3406],\n",
      "        [0.3403],\n",
      "        [0.3377],\n",
      "        [0.3416],\n",
      "        [0.3445],\n",
      "        [0.3381],\n",
      "        [0.3390],\n",
      "        [0.3435],\n",
      "        [0.3427],\n",
      "        [0.3390],\n",
      "        [0.3409]], device='mps:0')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (141,1) (4435556,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m test_y = torch.cat([i.y \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m loader_test.dataset]).numpy()\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Accuracy\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m val_acc = (\u001b[43m(\u001b[49m\u001b[43mval_preds\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m).mean()\n\u001b[32m     21\u001b[39m test_acc = ((test_preds > \u001b[32m0.5\u001b[39m) == (test_y > \u001b[32m0.5\u001b[39m)).mean()\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mValidation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: operands could not be broadcast together with shapes (141,1) (4435556,1) "
     ]
    }
   ],
   "source": [
    "# Run inference on model and extract val and test predictions\n",
    "def run_inference(model, loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            preds.append(torch.sigmoid(model(batch).to(device)))\n",
    "        preds = torch.cat(preds)\n",
    "    return preds.cpu().numpy()\n",
    "\n",
    "test_preds = run_inference(model, loader_test)\n",
    "val_preds = run_inference(model, loader_val)\n",
    "\n",
    "# Truth values\n",
    "val_y = torch.cat([i.y for i in loader_val.dataset]).numpy()\n",
    "test_y = torch.cat([i.y for i in loader_test.dataset]).numpy()\n",
    "\n",
    "# Accuracy\n",
    "val_acc = ((val_preds > 0.5) == (val_y > 0.5)).mean()\n",
    "test_acc = ((test_preds > 0.5) == (test_y > 0.5)).mean()\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c065f991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64206445],\n",
       "       [0.6422967 ],\n",
       "       [0.64196926],\n",
       "       [0.6422225 ],\n",
       "       [0.6422225 ],\n",
       "       [0.6420662 ],\n",
       "       [0.64199936],\n",
       "       [0.6422756 ],\n",
       "       [0.6420555 ],\n",
       "       [0.6420377 ],\n",
       "       [0.6421128 ],\n",
       "       [0.6422078 ],\n",
       "       [0.64195794],\n",
       "       [0.6420672 ],\n",
       "       [0.64235276],\n",
       "       [0.6420513 ],\n",
       "       [0.64204603],\n",
       "       [0.64221585],\n",
       "       [0.64186937],\n",
       "       [0.6421888 ],\n",
       "       [0.6420925 ],\n",
       "       [0.64205223],\n",
       "       [0.64212006],\n",
       "       [0.6421229 ],\n",
       "       [0.6419817 ],\n",
       "       [0.64213896],\n",
       "       [0.6420181 ],\n",
       "       [0.64212203],\n",
       "       [0.64219075],\n",
       "       [0.6419237 ],\n",
       "       [0.64202994],\n",
       "       [0.64213157],\n",
       "       [0.6421087 ],\n",
       "       [0.6421087 ],\n",
       "       [0.6418728 ],\n",
       "       [0.64201194],\n",
       "       [0.64207745],\n",
       "       [0.64219904],\n",
       "       [0.6419337 ],\n",
       "       [0.6422196 ],\n",
       "       [0.64210004],\n",
       "       [0.64209455],\n",
       "       [0.6420129 ],\n",
       "       [0.6419739 ],\n",
       "       [0.6419706 ],\n",
       "       [0.6419245 ],\n",
       "       [0.64232755],\n",
       "       [0.6421593 ],\n",
       "       [0.64205176],\n",
       "       [0.642329  ],\n",
       "       [0.6420411 ],\n",
       "       [0.6421193 ],\n",
       "       [0.64180833],\n",
       "       [0.64212847],\n",
       "       [0.6419827 ],\n",
       "       [0.6418213 ],\n",
       "       [0.6422779 ],\n",
       "       [0.64179546],\n",
       "       [0.6420193 ],\n",
       "       [0.64205897],\n",
       "       [0.6422529 ],\n",
       "       [0.64238644],\n",
       "       [0.6420278 ],\n",
       "       [0.64196813],\n",
       "       [0.64200294],\n",
       "       [0.64208686],\n",
       "       [0.6419199 ],\n",
       "       [0.6421175 ],\n",
       "       [0.6420597 ],\n",
       "       [0.6419765 ],\n",
       "       [0.64227504],\n",
       "       [0.64192027],\n",
       "       [0.6421509 ],\n",
       "       [0.6419093 ],\n",
       "       [0.6421536 ],\n",
       "       [0.64230084],\n",
       "       [0.6420837 ],\n",
       "       [0.64203095],\n",
       "       [0.6419886 ],\n",
       "       [0.6422382 ],\n",
       "       [0.64210385],\n",
       "       [0.641981  ],\n",
       "       [0.64202183],\n",
       "       [0.6421132 ],\n",
       "       [0.64195293],\n",
       "       [0.6421431 ],\n",
       "       [0.6421476 ],\n",
       "       [0.64192706],\n",
       "       [0.6420625 ],\n",
       "       [0.6419727 ],\n",
       "       [0.6419999 ],\n",
       "       [0.642085  ],\n",
       "       [0.6423078 ],\n",
       "       [0.64201444],\n",
       "       [0.64212215],\n",
       "       [0.6421839 ],\n",
       "       [0.64186746],\n",
       "       [0.6421633 ],\n",
       "       [0.6420807 ],\n",
       "       [0.64201415],\n",
       "       [0.6419469 ],\n",
       "       [0.64205146],\n",
       "       [0.6420814 ],\n",
       "       [0.6421683 ],\n",
       "       [0.64201474],\n",
       "       [0.6419642 ],\n",
       "       [0.64224017],\n",
       "       [0.6422157 ],\n",
       "       [0.6421868 ],\n",
       "       [0.64195716],\n",
       "       [0.6421178 ],\n",
       "       [0.6420446 ],\n",
       "       [0.64212924],\n",
       "       [0.64209574],\n",
       "       [0.64202595],\n",
       "       [0.6421551 ],\n",
       "       [0.6421277 ],\n",
       "       [0.64195967],\n",
       "       [0.6420408 ],\n",
       "       [0.6421763 ],\n",
       "       [0.6418434 ],\n",
       "       [0.6419513 ],\n",
       "       [0.6420873 ],\n",
       "       [0.64205176],\n",
       "       [0.64213014],\n",
       "       [0.6420208 ],\n",
       "       [0.64164174],\n",
       "       [0.6421409 ],\n",
       "       [0.6424415 ],\n",
       "       [0.6420878 ],\n",
       "       [0.64206696],\n",
       "       [0.6420481 ],\n",
       "       [0.6419031 ],\n",
       "       [0.6421184 ],\n",
       "       [0.64228135],\n",
       "       [0.64192295],\n",
       "       [0.6419765 ],\n",
       "       [0.642225  ],\n",
       "       [0.642184  ],\n",
       "       [0.6419743 ],\n",
       "       [0.6420815 ]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "497d0f7a-e5a7-4cff-9054-e32ae89dd143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/00.02\n",
      "shape preds_test: (177, 1)\n",
      "shape test_y: (5472684, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (177,1) (5472684,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshape preds_test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpreds_test.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshape test_y: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_y.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     results[p]={\u001b[33m'\u001b[39m\u001b[33mtest_accuracy\u001b[39m\u001b[33m'\u001b[39m: (\u001b[43mpreds_test\u001b[49m\u001b[43m==\u001b[49m\u001b[43mtest_y\u001b[49m).astype(\u001b[38;5;28mfloat\u001b[39m).mean(),\n\u001b[32m      9\u001b[39m      \u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m:(preds_val==val_y).astype(\u001b[38;5;28mfloat\u001b[39m).mean()}\n\u001b[32m     10\u001b[39m     results = pd.DataFrame(results)\n\u001b[32m     11\u001b[39m results.columns = [os.path.split(i)[-\u001b[32m1\u001b[39m].replace(\u001b[33m'\u001b[39m\u001b[33m.pkl\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m results.columns]\n",
      "\u001b[31mValueError\u001b[39m: operands could not be broadcast together with shapes (177,1) (5472684,1) "
     ]
    }
   ],
   "source": [
    "results = dict()\n",
    "print(PATH_DATA)\n",
    "for p in glob(os.path.join(PATH_DATA,'*.pkl')): \n",
    "    preds_test = joblib.load(p)['preds_test']>=0.5\n",
    "    preds_val =joblib.load(p)['preds_val']>=0.5\n",
    "    print(f\"shape preds_test: {preds_test.shape}\")\n",
    "    print(f\"shape test_y: {test_y.shape}\")\n",
    "    results[p]={'test_accuracy': (preds_test==test_y).astype(float).mean(),\n",
    "     'val_accuracy':(preds_val==val_y).astype(float).mean()}\n",
    "    results = pd.DataFrame(results)\n",
    "results.columns = [os.path.split(i)[-1].replace('.pkl','') for i in results.columns]\n",
    "results = results.T.sort_values('val_accuracy', ascending = False)\n",
    "results.index = pd.MultiIndex.from_tuples([tuple(i.split('_')) for i in results.index])\n",
    "results.index.names = ['#layers','#params']\n",
    "results.to_csv(os.path.join(PATH_DATA, 'results.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3305321c-ab2e-4b06-a70d-f1ce2e6580ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#layers</th>\n",
       "      <th>#params</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>1000000</th>\n",
       "      <td>0.994750</td>\n",
       "      <td>0.994493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500000</th>\n",
       "      <td>0.994401</td>\n",
       "      <td>0.994209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>1000000</th>\n",
       "      <td>0.993834</td>\n",
       "      <td>0.993719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>100000</th>\n",
       "      <td>0.993913</td>\n",
       "      <td>0.993667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>500000</th>\n",
       "      <td>0.993656</td>\n",
       "      <td>0.993433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1000000</th>\n",
       "      <td>0.992984</td>\n",
       "      <td>0.992853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500000</th>\n",
       "      <td>0.992865</td>\n",
       "      <td>0.992497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>100000</th>\n",
       "      <td>0.992658</td>\n",
       "      <td>0.992375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>100000</th>\n",
       "      <td>0.990710</td>\n",
       "      <td>0.990459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 test_accuracy  val_accuracy\n",
       "#layers #params                             \n",
       "4       1000000       0.994750      0.994493\n",
       "        500000        0.994401      0.994209\n",
       "3       1000000       0.993834      0.993719\n",
       "4       100000        0.993913      0.993667\n",
       "3       500000        0.993656      0.993433\n",
       "2       1000000       0.992984      0.992853\n",
       "        500000        0.992865      0.992497\n",
       "3       100000        0.992658      0.992375\n",
       "2       100000        0.990710      0.990459"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0e3dd0ba-e981-4c47-852d-14c66aeb5c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy 0.9947501079908871\n"
     ]
    }
   ],
   "source": [
    "print('The Accuracy', results.iloc[0]['test_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d4d99c-701d-4b02-9e24-cf80034fd80a",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e8473a-996c-46a5-8dec-88948ff9da82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd971d8-879e-4a50-bbcb-84323ccb0220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359bd6be-ce59-40f1-98d9-d61e6b6017d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "543661b5-fc2d-4d4d-b2eb-d05270fbbd15",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asdfasdfasfd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m asdfasdfasfd\n",
      "\u001b[31mNameError\u001b[39m: name 'asdfasdfasfd' is not defined"
     ]
    }
   ],
   "source": [
    "asdfasdfasfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c828c0e9-5b48-4bc7-b401-4f620fd682f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for n_layers in tqdm([3,2,4]): \n",
    "    for target_params in tqdm([100_000,500_000,1_000_000]): \n",
    "        print(n_layers, target_params)\n",
    "        # Find out the hyperparameteres yielding #params = target_params\n",
    "        def objective(h):\n",
    "            return count_parameters(InteractionNetwork(int(h),n_layers)) - target_params\n",
    "        optimal_h = int(root_scalar(objective, bracket=[1, 3000], method='bisect').root)\n",
    "        optimal_h= pd.Series({optimal_h:target_params-count_parameters(InteractionNetwork(optimal_h, n_layers)),\n",
    "                    optimal_h-1:target_params-count_parameters(InteractionNetwork(optimal_h-1,n_layers)),\n",
    "                    optimal_h+1:target_params-count_parameters(InteractionNetwork(optimal_h+1,n_layers))}).abs().idxmin()\n",
    "        \n",
    "        model = InteractionNetwork(optimal_h,n_layers).to(device)\n",
    "        lr = LR\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "        best_val_loss = float('inf')\n",
    "        epochs_no_improve, epochs_no_improve2 = 0,0\n",
    "        best_model_state = None\n",
    "        stats = []\n",
    "        best = None\n",
    "        # Print header once\n",
    "        print(f\"{'Epoch':>5} | {'Train Loss':>10} | {'Val Loss':>9} | {'Val Acc':>8} | {'Test Acc':>9}\")\n",
    "        print(\"-\" * 50)\n",
    "        for epoch in trange(MAX_EPOCHS):\n",
    "            train_loss = train_epoch(model, loader_train, optimizer)   \n",
    "            preds_val, actuals_val, acc_val, val_loss = evaluate(model,loader_val)\n",
    "            preds_test, actuals_test, acc_test, test_loss = evaluate(model,loader_test)\n",
    "            \n",
    "            stats.append({'train_loss':train_loss, 'val_loss':val_loss, 'acc_val':acc_val, 'acc_test':acc_test})\n",
    "            if val_loss < best_val_loss: \n",
    "                print(f\"{epoch+1:5d} | {train_loss:10.4f} | {val_loss:9.4f} | {acc_val:8.4f} | {acc_test:9.4f} *\")\n",
    "                best_val_loss = val_loss\n",
    "                epochs_no_improve = 0\n",
    "                epochs_no_improve2 = 0\n",
    "                best = {'model_state': {k: v.cpu() for k, v in model.state_dict().items()},\n",
    "                        'preds_test':preds_test, 'preds_val':preds_val}        \n",
    "            else:\n",
    "                print(f\"{epoch+1:5d} | {train_loss:10.4f} | {val_loss:9.4f} | {acc_val:8.4f} | {acc_test:9.4f}\")\n",
    "                epochs_no_improve += 1\n",
    "                epochs_no_improve2 += 1\n",
    "        \n",
    "            if epochs_no_improve >= TOLERANCE:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "            if epochs_no_improve2 >= LR_TOLERANCE:\n",
    "                if lr >=1.0e-8:\n",
    "                    lr/=10\n",
    "                print(f\"LR reduction to {lr}\")\n",
    "        os.makedirs(PATH_DATA, exist_ok=True)\n",
    "        joblib.dump(best, os.path.join(PATH_DATA, f\"{n_layers}_{target_params}.pkl\"))\n",
    "        \n",
    "        stats = pd.DataFrame(stats)\n",
    "        stats[['train_loss','val_loss']].plot(figsize = (15,4))\n",
    "        plt.show()\n",
    "        stats[['acc_val','acc_test']].plot(figsize = (15,4))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5612fe45-35a1-4990-8c4f-0fb27f96a6ad",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409092eb-d3db-4317-8f16-532759f3a52b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn-class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
