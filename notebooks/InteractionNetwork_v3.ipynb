{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d71bc261-6e78-4691-90ad-8e98eecc3221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import zipfile\n",
    "# from tqdm.auto import tqdm, trange # original\n",
    "from tqdm.notebook import tqdm, trange # fix for newline issue?\n",
    "from glob import glob\n",
    "from joblib import delayed, Parallel\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric as pyg\n",
    "import zipfile, os\n",
    "import torch\n",
    "import copy\n",
    "from torch import nn\n",
    "import networkx as nx\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm.auto import trange\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.neighbors import KNeighborsRegressor,RadiusNeighborsRegressor\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(\"Using device:\", device)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU, Sigmoid\n",
    "import torch.optim as optim\n",
    "import joblib\n",
    "import gc\n",
    "from scipy.optimize import root_scalar\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "PATH_DATA0 = '../data/00.01'\n",
    "PATH_DATA = '../data/00.02'\n",
    "RANDOM_SEED =0\n",
    "np.random.seed(RANDOM_SEED)  \n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52d8520-ae75-4eb4-9861-d8180b66a491",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42fe8bb8-066b-4b6b-a8f6-54e8a90c992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRITERION = nn.BCEWithLogitsLoss()\n",
    "LR = 0.001\n",
    "TOLERANCE = 20\n",
    "LR_TOLERANCE= 5\n",
    "MAX_EPOCHS = 200\n",
    "BATCH_SIZE =2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe91bb8-0c7c-48d2-a847-8d49edbb98fe",
   "metadata": {},
   "source": [
    "# Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c57214d9-6e6a-4ecf-ae09-238372e64216",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = pyg.loader.DataLoader(\n",
    "    pd.read_pickle(os.path.join(PATH_DATA0, 'graphs','max_prob_10_subsample_0.1','graphs_train.pkl')).tolist(),\n",
    "    batch_size = BATCH_SIZE,shuffle = True)\n",
    "loader_val = pyg.loader.DataLoader(\n",
    "    pd.read_pickle(os.path.join(PATH_DATA0, 'graphs','max_prob_10_subsample_0.1','graphs_val.pkl')).tolist(),batch_size = BATCH_SIZE\n",
    "    ,shuffle = False)\n",
    "loader_test = pyg.loader.DataLoader(\n",
    "    pd.read_pickle(os.path.join(PATH_DATA0, 'graphs','max_prob_10_subsample_0.1','graphs_test.pkl')).tolist(),batch_size = BATCH_SIZE\n",
    "    ,shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2222d194-3ee1-42b0-998b-0c76b5ca8d0c",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf055fc6-4688-4670-8bc5-907010be4eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationalModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, n_layers):\n",
    "        super(RelationalModel, self).__init__()\n",
    "\n",
    "        layers = [nn.Linear(input_size, hidden_size), \n",
    "                 nn.ReLU()]\n",
    "        if n_layers>=2:\n",
    "            for _ in range(n_layers - 1):\n",
    "                layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "                layers.append(nn.ReLU())\n",
    "\n",
    "        layers.append(nn.Linear(hidden_size, output_size))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "class ObjectModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, n_layers):\n",
    "        super(ObjectModel, self).__init__()\n",
    "\n",
    "        layers = [nn.Linear(input_size, hidden_size), \n",
    "                 nn.ReLU()]\n",
    "        if n_layers>=2:\n",
    "            for _ in range(n_layers - 1):\n",
    "                layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "                layers.append(nn.ReLU())\n",
    "\n",
    "        layers.append(nn.Linear(hidden_size, output_size))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, C):\n",
    "        return self.layers(C)\n",
    "class InteractionNetwork(MessagePassing):\n",
    "    def __init__(self, hidden_size, n_layers):\n",
    "        super(InteractionNetwork, self).__init__(aggr='add', \n",
    "                                                 flow='source_to_target')\n",
    "        self.R1 = RelationalModel(10, 4, hidden_size, n_layers)\n",
    "        self.O = ObjectModel(7, 3, hidden_size, n_layers)\n",
    "        self.R2 = RelationalModel(10, 1, hidden_size, n_layers)\n",
    "        self.E: Tensor = Tensor()\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor) -> Tensor:\n",
    "\n",
    "        # propagate_type: (x: Tensor, edge_attr: Tensor)\n",
    "        x_tilde = self.propagate(edge_index, x=x, edge_attr=edge_attr, size=None)\n",
    "\n",
    "        m2 = torch.cat([x_tilde[edge_index[1]],\n",
    "                        x_tilde[edge_index[0]],\n",
    "                        self.E], dim=1)\n",
    "        return self.R2(m2)\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        # x_i --> incoming\n",
    "        # x_j --> outgoing        \n",
    "        m1 = torch.cat([x_i, x_j, edge_attr], dim=1)\n",
    "        self.E = self.R1(m1)\n",
    "        return self.E\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        c = torch.cat([x, aggr_out], dim=1)\n",
    "        return self.O(c) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e474f636-44c5-4064-b74d-2715dfe92888",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bf42440-53fd-4ca4-84de-2752fcacb1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return trainable_params\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, actuals = [],[]\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            preds.append(torch.sigmoid(model(batch.x, batch.edge_index, batch.edge_attr)))\n",
    "            actuals.append(batch.y)\n",
    "        preds = torch.cat(preds)\n",
    "        actuals = torch.cat(actuals)\n",
    "        acc = ((preds>0.5)==(actuals>0.5)).type(torch.float).mean().item()\n",
    "        entropy = CRITERION(preds, actuals.float()).item()\n",
    "    model.train()\n",
    "    return preds.cpu().numpy(), actuals.cpu().numpy(), acc, entropy\n",
    "def train_epoch(model, loader_train,optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in tqdm(loader_train, leave = False):\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        loss = CRITERION(output, batch.y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * batch.num_graphs\n",
    "    train_loss /= len(loader_train)    \n",
    "    return train_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff5c058-e13a-4203-9aff-6d8706678e06",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2ee8b9-8fb9-46cd-832a-25d4d9b091a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3822360f37964f65a688c58644bf3727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903e6fc2f85d4824a6ce3ee42814f32d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1000000\n",
      "(1) Optimal h: 571\n",
      "(2) Optimal h: 571\n",
      "Epoch | Train Loss |  Val Loss |  Val Acc |  Test Acc\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef3124f50244805947636f877f8c186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909b96323bbf4b229d0f066e6fa92c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 |     0.5146 |    0.4199 |   0.9236 |    0.9261 *\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01bc7ac6a4a482c945b41ef4041619d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2 |     0.3648 |    0.4131 |   0.9357 |    0.9373 *\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2fbb27cae843f7b5c86af0ea1185ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    3 |     0.3707 |    0.4144 |   0.9303 |    0.9329\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec46c27855540c89befcfc0deedd20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    4 |     0.3159 |    0.4081 |   0.9425 |    0.9445 *\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c290be4015ba4fea826270424b786812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    5 |     0.2674 |    0.4031 |   0.9505 |    0.9519 *\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f8d8dd76b9462399d81cffe101ffca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    6 |     0.2418 |    0.4006 |   0.9536 |    0.9548 *\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29754ea510ea432a988dfe09099bfce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    7 |     0.2472 |    0.4008 |   0.9531 |    0.9541\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c82cebecc246d18bfe5d990e657265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8 |     0.2222 |    0.3999 |   0.9556 |    0.9569 *\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9443a5538c4f23997d31c9c37e6095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available():\n\u001b[32m     67\u001b[39m         torch.cuda.empty_cache()\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m                    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn_layers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m                    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarget_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1_000_000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m100_000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m                                               \u001b[49m\u001b[32;43m500_000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gnn-class/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1916\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gnn-class/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1849\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mf\u001b[39m\u001b[34m(n_layers, target_params)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m trange(MAX_EPOCHS):\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     train_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m   \n\u001b[32m     29\u001b[39m     preds_val, actuals_val, acc_val, val_loss = evaluate(model,loader_val)\n\u001b[32m     30\u001b[39m     preds_test, actuals_test, acc_test, test_loss = evaluate(model,loader_test)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, loader_train, optimizer)\u001b[39m\n\u001b[32m     24\u001b[39m output = model(batch.x, batch.edge_index, batch.edge_attr)\n\u001b[32m     25\u001b[39m loss = CRITERION(output, batch.y.float())\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m optimizer.step()\n\u001b[32m     28\u001b[39m train_loss += loss.item() * batch.num_graphs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gnn-class/lib/python3.11/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gnn-class/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gnn-class/lib/python3.11/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def f(n_layers,target_params):\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    print(n_layers, target_params)\n",
    "    # Find out the hyperparameteres yielding #params = target_params\n",
    "    def objective(h):\n",
    "        return count_parameters(InteractionNetwork(int(h),n_layers)) - target_params\n",
    "    optimal_h = int(root_scalar(objective, bracket=[1, 50000], method='bisect').root)\n",
    "    print(f\"(1) Optimal h: {optimal_h}\")\n",
    "    optimal_h= pd.Series({optimal_h:target_params-count_parameters(InteractionNetwork(optimal_h, n_layers)),\n",
    "                optimal_h-1:target_params-count_parameters(InteractionNetwork(optimal_h-1,n_layers)),\n",
    "                optimal_h+1:target_params-count_parameters(InteractionNetwork(optimal_h+1,n_layers))}).abs().idxmin()\n",
    "    print(f\"(2) Optimal h: {optimal_h}\")\n",
    "    \n",
    "    model = InteractionNetwork(optimal_h,n_layers).to(device)\n",
    "    lr = LR\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve, epochs_no_improve2 = 0,0\n",
    "    best_model_state = None\n",
    "    stats = []\n",
    "    best = None\n",
    "    # Print header once\n",
    "    print(f\"{'Epoch':>5} | {'Train Loss':>10} | {'Val Loss':>9} | {'Val Acc':>8} | {'Test Acc':>9}\")\n",
    "    print(\"-\" * 50)\n",
    "    for epoch in trange(MAX_EPOCHS):\n",
    "        train_loss = train_epoch(model, loader_train, optimizer)   \n",
    "        preds_val, actuals_val, acc_val, val_loss = evaluate(model,loader_val)\n",
    "        preds_test, actuals_test, acc_test, test_loss = evaluate(model,loader_test)\n",
    "        \n",
    "        stats.append({'train_loss':train_loss, 'val_loss':val_loss, 'acc_val':acc_val, 'acc_test':acc_test})\n",
    "        if val_loss < best_val_loss: \n",
    "            print(f\"{epoch+1:5d} | {train_loss:10.4f} | {val_loss:9.4f} | {acc_val:8.4f} | {acc_test:9.4f} *\")\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            epochs_no_improve2 = 0\n",
    "            best = {'model_state': {k: v.cpu() for k, v in model.state_dict().items()},\n",
    "                    'preds_test':preds_test, 'preds_val':preds_val}        \n",
    "        else:\n",
    "            print(f\"{epoch+1:5d} | {train_loss:10.4f} | {val_loss:9.4f} | {acc_val:8.4f} | {acc_test:9.4f}\")\n",
    "            epochs_no_improve += 1\n",
    "            epochs_no_improve2 += 1\n",
    "\n",
    "        if epochs_no_improve >= TOLERANCE:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "        if epochs_no_improve2 >= LR_TOLERANCE:\n",
    "            if lr >=1.0e-8:\n",
    "                lr/=10\n",
    "            print(f\"LR reduction to {lr}\")\n",
    "    best['stats'] = stats\n",
    "    os.makedirs(PATH_DATA, exist_ok=True)\n",
    "    joblib.dump(best, os.path.join(PATH_DATA, f\"{n_layers}_{target_params}.pkl\"))\n",
    "    \n",
    "    stats = pd.DataFrame(stats)\n",
    "    stats[['train_loss','val_loss']].plot(figsize = (15,4))\n",
    "    plt.show()\n",
    "    stats[['acc_val','acc_test']].plot(figsize = (15,4))\n",
    "    plt.show()\n",
    "    del model\n",
    "    del train_loss\n",
    "    del optimizer\n",
    "\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "Parallel(n_jobs=1)(delayed(f)(n_layers,target_params)\n",
    "                    for n_layers in tqdm([2,3,4])\n",
    "                    for target_params in tqdm([1_000_000,100_000,\n",
    "                                               500_000,]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e401f1-823e-4422-8908-775d77c471f8",
   "metadata": {},
   "source": [
    "# Summary of the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ab51456-0db4-4a57-b2f9-e5e37bb9d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_pickle(os.path.join(PATH_DATA0, 'graphs','max_prob_10_subsample_0.1','graphs_val.pkl'))\n",
    "test = pd.read_pickle(os.path.join(PATH_DATA0, 'graphs','max_prob_10_subsample_0.1','graphs_test.pkl'))\n",
    "val_y = torch.cat([i.y for i in val.values]).numpy()\n",
    "test_y = torch.cat([i.y for i in test.values]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08747524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run inference on validation and test sets\n",
    "def run_inference(model, loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            preds.append(torch.sigmoid(model(batch.x, batch.edge_index, batch.edge_attr)))\n",
    "        preds = torch.cat(preds)\n",
    "    return preds.cpu().numpy()\n",
    "\n",
    "val = run_inference(model, loader_val)\n",
    "test = run_inference(model, loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d0f7a-e5a7-4cff-9054-e32ae89dd143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (177,1) (5472684,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m     preds_val =joblib.load(p)[\u001b[33m'\u001b[39m\u001b[33mpreds_val\u001b[39m\u001b[33m'\u001b[39m]>=\u001b[32m0.5\u001b[39m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(preds_test.shape)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     results[p]={\u001b[33m'\u001b[39m\u001b[33mtest_accuracy\u001b[39m\u001b[33m'\u001b[39m: (\u001b[43mpreds_test\u001b[49m\u001b[43m==\u001b[49m\u001b[43mtest_y\u001b[49m).astype(\u001b[38;5;28mfloat\u001b[39m).mean(),\n\u001b[32m      7\u001b[39m      \u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m:(preds_val==val_y).astype(\u001b[38;5;28mfloat\u001b[39m).mean()}\n\u001b[32m      8\u001b[39m     results = pd.DataFrame(results)\n\u001b[32m      9\u001b[39m results.columns = [os.path.split(i)[-\u001b[32m1\u001b[39m].replace(\u001b[33m'\u001b[39m\u001b[33m.pkl\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m results.columns]\n",
      "\u001b[31mValueError\u001b[39m: operands could not be broadcast together with shapes (177,1) (5472684,1) "
     ]
    }
   ],
   "source": [
    "results = dict()\n",
    "for p in glob(os.path.join(PATH_DATA,'*.pkl')): \n",
    "    preds_test = joblib.load(p)['preds_test']>=0.5\n",
    "    preds_val =joblib.load(p)['preds_val']>=0.5\n",
    "    print(preds_test)\n",
    "    results[p]={'test_accuracy': (preds_test==test_y).astype(float).mean(),\n",
    "     'val_accuracy':(preds_val==val_y).astype(float).mean()}\n",
    "    results = pd.DataFrame(results)\n",
    "results.columns = [os.path.split(i)[-1].replace('.pkl','') for i in results.columns]\n",
    "results = results.T.sort_values('val_accuracy', ascending = False)\n",
    "results.index = pd.MultiIndex.from_tuples([tuple(i.split('_')) for i in results.index])\n",
    "results.index.names = ['#layers','#params']\n",
    "results.to_csv(os.path.join(PATH_DATA, 'results.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3305321c-ab2e-4b06-a70d-f1ce2e6580ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#layers</th>\n",
       "      <th>#params</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>1000000</th>\n",
       "      <td>0.994750</td>\n",
       "      <td>0.994493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500000</th>\n",
       "      <td>0.994401</td>\n",
       "      <td>0.994209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>1000000</th>\n",
       "      <td>0.993834</td>\n",
       "      <td>0.993719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>100000</th>\n",
       "      <td>0.993913</td>\n",
       "      <td>0.993667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>500000</th>\n",
       "      <td>0.993656</td>\n",
       "      <td>0.993433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1000000</th>\n",
       "      <td>0.992984</td>\n",
       "      <td>0.992853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500000</th>\n",
       "      <td>0.992865</td>\n",
       "      <td>0.992497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>100000</th>\n",
       "      <td>0.992658</td>\n",
       "      <td>0.992375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>100000</th>\n",
       "      <td>0.990710</td>\n",
       "      <td>0.990459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 test_accuracy  val_accuracy\n",
       "#layers #params                             \n",
       "4       1000000       0.994750      0.994493\n",
       "        500000        0.994401      0.994209\n",
       "3       1000000       0.993834      0.993719\n",
       "4       100000        0.993913      0.993667\n",
       "3       500000        0.993656      0.993433\n",
       "2       1000000       0.992984      0.992853\n",
       "        500000        0.992865      0.992497\n",
       "3       100000        0.992658      0.992375\n",
       "2       100000        0.990710      0.990459"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0e3dd0ba-e981-4c47-852d-14c66aeb5c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy 0.9947501079908871\n"
     ]
    }
   ],
   "source": [
    "print('The Accuracy', results.iloc[0]['test_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d4d99c-701d-4b02-9e24-cf80034fd80a",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e8473a-996c-46a5-8dec-88948ff9da82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd971d8-879e-4a50-bbcb-84323ccb0220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359bd6be-ce59-40f1-98d9-d61e6b6017d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "543661b5-fc2d-4d4d-b2eb-d05270fbbd15",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asdfasdfasfd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m asdfasdfasfd\n",
      "\u001b[31mNameError\u001b[39m: name 'asdfasdfasfd' is not defined"
     ]
    }
   ],
   "source": [
    "asdfasdfasfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c828c0e9-5b48-4bc7-b401-4f620fd682f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for n_layers in tqdm([3,2,4]): \n",
    "    for target_params in tqdm([100_000,500_000,1_000_000]): \n",
    "        print(n_layers, target_params)\n",
    "        # Find out the hyperparameteres yielding #params = target_params\n",
    "        def objective(h):\n",
    "            return count_parameters(InteractionNetwork(int(h),n_layers)) - target_params\n",
    "        optimal_h = int(root_scalar(objective, bracket=[1, 3000], method='bisect').root)\n",
    "        optimal_h= pd.Series({optimal_h:target_params-count_parameters(InteractionNetwork(optimal_h, n_layers)),\n",
    "                    optimal_h-1:target_params-count_parameters(InteractionNetwork(optimal_h-1,n_layers)),\n",
    "                    optimal_h+1:target_params-count_parameters(InteractionNetwork(optimal_h+1,n_layers))}).abs().idxmin()\n",
    "        \n",
    "        model = InteractionNetwork(optimal_h,n_layers).to(device)\n",
    "        lr = LR\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "        best_val_loss = float('inf')\n",
    "        epochs_no_improve, epochs_no_improve2 = 0,0\n",
    "        best_model_state = None\n",
    "        stats = []\n",
    "        best = None\n",
    "        # Print header once\n",
    "        print(f\"{'Epoch':>5} | {'Train Loss':>10} | {'Val Loss':>9} | {'Val Acc':>8} | {'Test Acc':>9}\")\n",
    "        print(\"-\" * 50)\n",
    "        for epoch in trange(MAX_EPOCHS):\n",
    "            train_loss = train_epoch(model, loader_train)   \n",
    "            preds_val, actuals_val, acc_val, val_loss = evaluate(model,loader_val)\n",
    "            preds_test, actuals_test, acc_test, test_loss = evaluate(model,loader_test)\n",
    "            \n",
    "            stats.append({'train_loss':train_loss, 'val_loss':val_loss, 'acc_val':acc_val, 'acc_test':acc_test})\n",
    "            if val_loss < best_val_loss: \n",
    "                print(f\"{epoch+1:5d} | {train_loss:10.4f} | {val_loss:9.4f} | {acc_val:8.4f} | {acc_test:9.4f} *\")\n",
    "                best_val_loss = val_loss\n",
    "                epochs_no_improve = 0\n",
    "                epochs_no_improve2 = 0\n",
    "                best = {'model_state': {k: v.cpu() for k, v in model.state_dict().items()},\n",
    "                        'preds_test':preds_test, 'preds_val':preds_val}        \n",
    "            else:\n",
    "                print(f\"{epoch+1:5d} | {train_loss:10.4f} | {val_loss:9.4f} | {acc_val:8.4f} | {acc_test:9.4f}\")\n",
    "                epochs_no_improve += 1\n",
    "                epochs_no_improve2 += 1\n",
    "        \n",
    "            if epochs_no_improve >= TOLERANCE:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "            if epochs_no_improve2 >= LR_TOLERANCE:\n",
    "                if lr >=1.0e-8:\n",
    "                    lr/=10\n",
    "                print(f\"LR reduction to {lr}\")\n",
    "        os.makedirs(PATH_DATA, exist_ok=True)\n",
    "        joblib.dump(best, os.path.join(PATH_DATA, f\"{n_layers}_{target_params}.pkl\"))\n",
    "        \n",
    "        stats = pd.DataFrame(stats)\n",
    "        stats[['train_loss','val_loss']].plot(figsize = (15,4))\n",
    "        plt.show()\n",
    "        stats[['acc_val','acc_test']].plot(figsize = (15,4))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5612fe45-35a1-4990-8c4f-0fb27f96a6ad",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409092eb-d3db-4317-8f16-532759f3a52b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn-class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
